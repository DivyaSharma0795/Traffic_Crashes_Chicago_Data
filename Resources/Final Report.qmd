---
title: "Data Modeling and Representation Final Project"
author: "Jiayi Zhou, Jiechen Li, Divya Sharma, Dhaval Potdar"
margin-width: 250px 0.5
format: pdf
fontsize: "10"
pdf: default
reference-location: margin
citation-location: margin
execute:
  echo: false
  warning: false
---

\pagebreak

# Abstract

As of September 2023, a total of 80,000 car accidents have been reported this year, in Chicago alone. In the last five years, an average of 110,000 accidents have been reported annually, leading to 21,000 injuries. About 60% of these crashes cost more than \$1500 in damages. With a 0.35% year-on-year increase in car ownership in Chicago[^1], these numbers are only expected to go up. One way for cities to combat this situation is to analyze conditions that pose the most risk to life and property, and introduce interventions such as road-side warnings, additional police patrolling, etc. in high risk areas and under high risk conditions. In this project, we analyze data on road crashes maintained by the city of Chicago between January 2022 and December 2022, and predict two quantities - (i) the time taken for the authorities to be notified about a certain crash, and (ii) whether the damage cost would exceed \$1500. We use data available at the time of accident such as the distance from downtown, time of day, visibility, precipitation, etc. to make predictions. In the exploratory data analysis phase however, we find it challenging to identify strong indicators for our outcome variables. The diagnostic plots of the models show strong evidence of non-linearity. Although our models would allow authorities to run simulations that would let them identify conditions that pose the most threat to drivers, as it stands, we would need to improve performance before they can be used reliably.

[^1]: Pearce, R. (n.d.). Forbes Advisor - Smart Financial Decisions Made Simple. Forbes Advisor. <https://www.forbes.com/advisor/>

# Introduction

The primary data source for this project is city of Chicago's official website[^2]. The dataset has information on crashes from 2015 to September 2023 and spans across 784K rows and 84 columns. However, for our analysis, we only consider data from 2022. This brings down the number of rows to 76,820. Some sample colums that we use for modeling are - time of day, day of week, and speed limit. We also use an external dataset sourced from an online proprietary weather data service[^3]. This dataset gives weather-related information such as precipitation, snow, visibility, etc. for Chicago for every day in our main dataset.

[^2]: City of Chicago \| Data Portal \| City of Chicago \| Data Portal. (n.d.). Chicago. <https://data.cityofchicago.org/>

[^3]: Weather Data & Weather API \| Visual Crossing. (n.d.). Www.visualcrossing.com. <https://www.visualcrossing.com/>

The goal of this analysis is to answer two questions:

1.  Given the conditions of a crash, how long does it take for authorities to be officially notified in minutes.

2.  Given the conditions of a crash, would the monetary damages be major (\>\$1500) or minor (\$\<1500).

Since it is not possible to gather data at the exact instant that a crash occurs, our models gives representative pictures as to what should be expected, given the conditions of a crash. These models can be used by authorities to identify crash conditions that pose the most threat to life and property. This in turn, would let authorities identify infrastructure gaps such as inadequate surveillance or lack of mobile coverage leading to a delay in notifying authorities about crashes. Also, certain conditions that lead to consistently higher monetary damages may signal a problem with road quality or inadequate speed restrictions. With a five-year average of over 100K annual accidents in Chicago, even a 1% average reduction in the time taken to notify authorities about a crash could save lives, and potentially save millions in damages annually.

# Methods

## Data

For the main dataset from Chicago's official website, we identified the correct data types for each of the variables and modified them accordingly. Then we extracted temporal features such as hour of day, day of week, and month of year from the crash timestamp. We used the crash latitude and longitude to calculate the distance of the crash from downtown Chicago using Haversine distance. We then left-joined the weather data onto the main dataset on the date column, and then did a sanity check to ensure no duplicates were introduced. Lastly, we checked for null and improbable values and removed them from the dataset.

## Models

**In reference to the first research question**[^4], our target variable is a continuous variable that indicates the time taken for authorities to be notified about a crash. The target variable is calculated as the time difference between the moment of the incidence, and the moment the police were first notified.

[^4]: Given the conditions of a crash, how long does it take for authorities to be officially notified in minutes?

The a priori selection of the predictor variables was made by analyzing patterns in the data that indicated a possible relationship with the target variable. We then chose the year 2022, for which we have the complete data. The reason we did this was because we observed significant variation in the data across years, which was difficult to model. We also limited the police notification time to 60 minutes, because the median of the distribution is at 25 minutes, and \>60 minutes represents only the trailing end of the distribution. The final model comprised of variables such as month of year, hour of day, traffic way type, distance to downtown and weather-related variables such as temperature, snowfall, and an interaction term between precipitation and month of year.

**In reference to the second research question**[^5], the dependent variable assesses whether monetary damages are categorized as major (\>\$1500) or minor (\$\<1500). We employed Logistic regression due to the binary nature of the outcome variable, which manifests as either major damages (\>\$1500) or minor damages (\$\<1500).

[^5]: Given the conditions of a crash, would the monetary damages be major (\>\$1500) or minor (\$\<1500)?

We selected the predictor variables basis their association with the outcome variable. The model incorporates explanatory variables such as the time of the crash, speed limit, distance to downtown, traffic way type, roadway surface condition, and weather-related factors like temperature, and snowfall.

## Model Assessment

**To assess the Linear Regression model**, we looked at the residual plots and found a pattern that indicated possible non-linearity. We then dove deeper into each of the predictors in the model and plotted scatter-plots for numeric variables, and box-plots for categorical variables, with the target variable on the y-axis. Indeed, we found that most of the variables had a mostly non-linear relationship with the target variable. As an alternative, we tried to model the log of the target variable, and still didn't see significant improvements. Upon examining the Q-Q Plot, we saw significant tail-behavior on both ends, which suggests that a linear model may not be the best choice for this problem.

**To assess multicollinearity within the Logistic Regression model**, we calculated the Variance Inflation Factor (VIF) score. A VIF score below 5 for all predictor variables suggested the absence of multicollinearity. Regarding influential points, the Cook's distance metric was utilized, and points exhibiting high Cook's distances were systematically eliminated. Subsequently, the model was refitted without these influential points, and Cook's distance was reevaluated.

\
For model performance evaluation, given our predictive objective, the ROC curve was employed to determine the optimal cutoff point. Simultaneously, a confusion matrix was utilized to assess the model, wherein accuracy, kappa, precision, and F1 score were pivotal. Given the larger than \$1,500 damage size indicating the severity of the accident, emphasis was placed on the true positive rate (also named sensitivity/recall).

# Results

```{r}
library(tidyverse)
library(pROC)
library(caret)
library(cvms)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)

base_data <- readRDS(file='df_cleaned_chicago_crashes.rds')

base_data_filtered_glm <- base_data %>% 
  rename(`Damage Class` = damage_class) %>% 
  filter(crash_date >= as.Date('2022-01-01') & crash_date <= as.Date('2022-12-31')) %>%
  rename(`Police Notified Time` = police_notified_time) 

base_data_filtered <- base_data %>% 
  filter(police_notified_time < 60) %>%
  filter(crash_date >= as.Date('2022-01-01') & crash_date <= as.Date('2022-12-31')) %>%
  rename(`Police Notified Time` = police_notified_time) 

```

## Exploratory Data Analysis

After processing the data using the aforementioned method, the dataset comprises 555,356 observations and 18 variables. 

In the context of the research focusing on police response time, we identified that the median notification time is 25 minutes, the mean is 110 minutes (equivalent to 1 hour and 50 minutes), and the maximum recorded time is 1440 minutes (representing 1 day).

Regarding the research question concerning damage size, our analysis revealed that 62% of the damages exceed $\$1,500$, falling into the "Major" category, while 38% of the damages are less than $\$1,500$, falling into the "Minor" category.

For the categorical data, we examined crash hour (ranging from 0 to 23 based on the hour of the day), crash day of the week (ranging from 0 to 7 corresponding to the day of the week), and crash month (spanning from January to December based on the month). Our findings revealed that crashes predominantly occurred during the most common times of the day, specifically between 12 PM and 4 PM, on the most common days of the week, namely Fridays and Saturdays, and during the most common crash monthsâ€”July, August, and September.

Additionally, we conducted a similar analysis for weather and lighting conditions, as well as road conditions. The results indicate that 65.6% of crashes transpire during daylight, 79.8% occur under clear weather conditions, and 44% take place on non-divided roads.

Furthermore, we examined the individual distributions of the numeric variables and observed highly skewed distributions. The accompanying plot illustrates some of these variables.

```{r}

#| label: fig-margin
#| fig-cap: "Distributions of Numeric Variables"
#| column: margin
#| message: false

plot1 <- base_data_filtered_glm %>%
  ggplot(aes(x=dist_to_dt)) +
  geom_histogram(binwidth=0.1, fill="#69b3a2", color="#e9ecef", alpha=0.9) +
  ggtitle("Dist. to Downtown") +
  xlab("Distance in Meters (logscale)") +
  ylab("Count") +
  # annotation_logticks() +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_continuous(name = "Number of Crashes", labels = scales::comma) +
  theme(plot.title = element_text(size=15)) + 
  scale_color_brewer(palette = "Okabe-Ito")

plot2 <- base_data_filtered_glm %>%
  ggplot(aes(x=visibility)) +
  geom_histogram(binwidth=0.1, fill="#69b3a2", color="#e9ecef", alpha=0.9) +
  ggtitle("Visibility") +
  xlab("Distance in Meters (logscale)") +
  ylab("Count") +
  # annotation_logticks() +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_continuous(name = "Number of Crashes", labels = scales::comma) +
  theme(plot.title = element_text(size=15))  + 
  scale_color_brewer(palette = "Okabe-Ito")

plot3 <- base_data_filtered_glm %>%
  ggplot(aes(x=precipitation)) +
  geom_histogram(binwidth=0.1, fill="#69b3a2", color="#e9ecef", alpha=0.9) +
  ggtitle("Precipitation") +
  xlab("Distance in Meters (logscale)") +
  ylab("Count") +
  # annotation_logticks() +
  scale_x_log10(
   breaks = scales::trans_breaks("log10", function(x) 10^x),
   labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_continuous(name = "Number of Crashes", labels = scales::comma) +
  theme(plot.title = element_text(size=15))


plot4 <- base_data_filtered_glm %>%
  ggplot(aes(x=temp)) +
  geom_histogram(binwidth=0.1, fill="#69b3a2", alpha=0.9) +
  ggtitle("Temperature") +
  xlab("Temperature") +
  ylab("Count") +
  # annotation_logticks() +
  # scale_x_log10(
  #  breaks = scales::trans_breaks("log10", function(x) 10^x),
  #  labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_y_continuous(name = "Number of Crashes", labels = scales::comma) +
  theme(plot.title = element_text(size=15))

grid.arrange(plot1, plot2, plot3, plot4, nrow = 2, ncol=2)
```

## Linear Regression Model

```{r}

lm_1 <- lm(`Police Notified Time` ~
           hr_of_day +
           trafficway_type +
           dist_to_dt +
           temp +
           precipitation * month_of_year +
           snow +
           snowdepth +
           visibility,
         data = base_data_filtered)
```

In developing the Linear Regression model, we hypothesized that the day of week, the hour of day and month of year, would indirectly indicate how much population of Chicago would be outdoors, and thus contain some information that would help predict how long it would take for police to be notified if an accident happened. However, we found no specific relationship between the day of week and police notification time. We did however, find slight variation in the police notification time basis the time of day.

```{r}
# 
# base_data_filtered %>% 
#   ggplot(., aes(x = day_of_week,  y = `Police Notified Time`))+ 
#   geom_boxplot(outlier.shape=NA)+
#   geom_jitter(aes(color = crash_hour)) +
#   # ylim(0, 300) +
#   theme_bw() + 
#   xlab("Day of Week") + 
#   ylab("Time taken to notify police upon accident (Minutes)")
```

We then looked at the traffic way type, hypothesizing that certain traffic ways such as four-way intersections would have more influx of traffic, thus making accidents more likely to be reported quicker. We did find variations in the distributions of police notification time and traffic-way type.

```{r}

#| label: fig-margin
#| fig-cap: "Traffic way type vs police notification time"
#| column: margin
#| message: false

base_data_filtered %>% 
  ggplot(., aes(x = trafficway_type,  y = `Police Notified Time`))+ 
  geom_boxplot(outlier.shape=NA)+
  # geom_jitter(aes(color = crash_hour)) +
  # ylim(0, 300) +
  theme_bw() + 
  xlab("Traffic Way Type") + 
  ylab("Police notification\n time (minutes)") +
  ggtitle("Variance of Police notification time by Traffic way type") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r}

# base_data_filtered %>% 
#   mutate(crash_hour = case_when(hr_of_day < 4 ~ "12 AM - 4 AM",
#                                 hr_of_day < 8 ~ "4 AM - 8 AM",
#                                 hr_of_day < 12 ~ "8 AM - 12 PM",
#                                 hr_of_day < 16 ~ "12 PM - 4 PM",
#                                 hr_of_day < 20 ~ "4 PM - 8 PM",
#                                 hr_of_day < 24 ~ "8 PM - 12 AM"),
#          crash_hour = factor(crash_hour, ordered=T, 
#                              levels = c("12 AM - 4 AM",
#                                         "4 AM - 8 AM",
#                                         "8 AM - 12 PM",
#                                         "12 PM - 4 PM",
#                                         "4 PM - 8 PM",
#                                         "8 PM - 12 AM"))) %>% 
#   ggplot(., aes(x = crash_hour,  y = `Police Notified Time`))+ 
#   geom_boxplot(outlier.shape=NA)+
#   # geom_jitter(aes(color = crash_hour)) +
#   # ylim(0, 300) +
#   theme_bw() + 
#   xlab("Time of the day") + 
#   ylab("Time taken to notify police upon accident (Minutes)")
```

Finally, since we were unable to find strong indicator variables for our target variable, we sought out additional data. More specifically, we sourced date-level weather data, hypothesizing that lower temperatures, or lower visibility would generally increase the time taken to report accidents. We also added distance from downtown Chicago as a variable and interaction between precipitation and month of year. Despite adding these additional variables, we only observed a slight increase in model performance. Our final model achieved an Adjusted R2 score of 4.5%. This indicated either that the variables needed to predict the outcome are simply not captured in the data, or that we would need a non-linear model to more strongly predict the outcome. The model summary can be viewed in the appendix section of this document.

```{r}

# base_data_filtered %>% 
#   ggplot(., aes(x = month_of_year,  y = `Police Notified Time`))+ 
#   geom_boxplot(outlier.shape=NA)+
#   # geom_jitter(aes(color = crash_hour)) +
#   # ylim(0, 300) +
#   theme_bw() + 
#   xlab("Month of year") + 
#   ylab("Time taken to notify police upon accident (Minutes)")
```

## Logistic Regression Model

```{r}

model_3 <- glm(`Damage Class` ~ 
                 # day_of_week + 
                 hr_of_day + 
                 speed_limit + 
                 dist_to_dt + 
                 visibility  +
                 roadway_surface_cond +
                 trafficway_type +
                 temp +
                 snow, 
               data = base_data_filtered_glm, family = "binomial")
```

In developing the Logistic Regression model for predicting car accident damage costs, we integrated key factors, notably the roadway surface condition, and visibility, considering the winter conditions of Chicago. The model showed a balanced approach to predicting damages, an important indicator of its unbiased nature, though this did not directly correlate with prediction accuracy.

```{r}
#| label: fig-margin5
#| fig-cap: "Predicted Probability of Higher Damage Class by Weather Condition"
#| column: margin
#| message: false

# Logistic regression for a categorical predictor (weather_condition)
df = base_data_filtered_glm %>% 
  rename(damage_class = `Damage Class`)
model_cat <- glm(damage_class ~ weather_condition, data = df, family = "binomial")
df_weather <- unique(df[, c("weather_condition", "damage_class")])
df_weather$prob <- predict(model_cat, newdata = df_weather, type = "response")
# Create a bar plot
ggplot(df_weather, aes(x = weather_condition, y = prob, fill = weather_condition)) +
  geom_bar(stat = "identity") +
  scale_fill_brewer(palette = "Set3") +
  ggtitle("Predicted Prob. of Higher Damage Class by Weather Condition") +
  xlab("Weather Condition") +
  ylab("Predicted Probability") +
  theme(
    axis.text.x = element_text(angle = 65, hjust = 1,),
    legend.position = "center"
  ) 
```

Our analysis for outliers using Cook's Distance revealed three notable cases, yet their presence did not significantly alter the model's performance. In assessing multicollinearity through the Variance Inflation Factor (VIF), we found that while certain variables like hour of a day had low VIF values, indicating clear independent contributions, others, particularly weather-related factors, showed higher VIF values. This suggested overlapping influences that could affect interpretability.

```{r}
#| label: fig-margin6
#| fig-cap: "Confusion Matrix for Logistic Regression"
#| column: margin
#| message: false
#| 
conf_mat_raw <- confusionMatrix(factor(ifelse(fitted(model_3) > 0.331, "Major", "Minor")), factor(base_data_filtered_glm$`Damage Class`), positive="Major", mode="everything")

conf_mat <- as_tibble(conf_mat_raw$table)


plot_confusion_matrix(conf_mat, 
                      prediction_col = 'Prediction',
                      target_col = 'Reference', 
                      counts_col = 'n', 
                      add_normalized = F, add_col_percentages = F, add_row_percentages = F)
```

By examining the The Receiver Operating Characteristic (ROC) curve of the model we identified the threshold value at 0.331. However, the confusion matrix was not indicative of strong performance, and overall accuracy stood at 40%. The model's negative Kappa value of -0.063 was particularly concerning, and indicated that the model was unable to uncover meaningful relationships in the data.

In essence, Logistic Regression's strength lies in its capacity to identify severe accidents, a crucial aspect of our study. Yet, the need for refinement is clear, especially in gathering stronger variables to model the outcome, or to use a more powerful class of models.

# Conclusion

The validity of any analysis relies on the accuracy of the assumptions made and the representativeness of the dataset. The strength of this analysis lied in its incorporation of numerous variables, including weather, road conditions, and distance to downtown, all of which were logically relevant to the assessment of damage size and the time it takes for a crash to be reported. However, modeling our outcome variables proved to be very challenging.

For the linear regression model, we found evidence of statistical significance in the traffic way type variable, and also in the interaction between the month of year and precipitation. However, with the Adjusted R2 score of 4.5% we conclude that our model is not sufficiently strong to be used for prediction purposes at this point.

For the logistic regression model, with an F1 score of 40%, it is equally evident that the models is unable to capture patterns in the data to confidently predict the damage class. Although the model has Precision of 62.5%, it struggles with a low recall of 28.5%. Most concerning is the Kappa value of -0.063, which is indicative of the model picking up on mostly noise in the data, rather than meaningful relationships.

\
Primarily, the presence of unknown values in a majority of the categorical variables made observing meaningful relationships difficult. Additionally, numerous unreasonable values (such as negative time taken for police to be notified) had to be removed from the original dataset since no explanation was found at the source. Furthermore, any relationships found in the dataset were largely counter-intuitive or non-linear.

\
Enhancements in the model's performance could be achieved with a more comprehensive dataset that accurately captures the nuances of crashes. We would also have to explore a more powerful class of models to capture the non-linearity in the dataset. A dataset of greater scope and accuracy would likely result in improvements, effectively addressing the limitations inherent in the current analysis.

\pagebreak

# Appendix

### Results for Linear Regression Model

#### Model Summary

The model achieved a 4.5% R2 score on the dataset. Below is the technical summary of the model.

```{r}

suppressWarnings(sjPlot::tab_model(lm_1, 
                                   show.r2 = F,
                                   show.obs = F, 
                                   show.se = T,
                                   title = "Linear Model Summary for Police Notified Time",
                                   pred.labels = c("intercept","hr of day","center","divided","barrier","driveway","five point","four way","L-intersect","not divided","not reported","one way","other","parking lot","ramp","roundabout","T-intersect","traffic route","unknown way","unknown intersect","Y-intersect","dist to dt","temp","precipitation","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","snow","snow depth","visibility","FebXPrecipitation","MarXPrecipitation","AprXPrecipitation","MayXPrecipitation","JunXPrecipitation","JulXPrecipitation","AugXPrecipitation","SepXPrecipitation","OctXPrecipitation","NovXPrecipitation","DecXPrecipitation")))

```

#### Q-Q Plot

The Q-Q plot shows strong tail-behavior.

```{r}

plot(lm_1, which=2)
```

### Results of Logistic Regression Model

#### Model Summary

Below is the technical summary of the Logistic Regression Model.

```{r}

suppressWarnings(sjPlot::tab_model(model_3, 
                                   show.r2 = F,
                                   show.obs = F, 
                                   show.se = T,
                                   string.se = "Std. Error",
                                   title = "Logistic Regression Summary for Damage Class",
                                   pred.labels = c("intercept","hr of day","speed limit","dist to dt","visibility","ice road","other road","sand road","snow road","unknown road","wet road","center","divided","barrier","driveway","five point","four way","L-intersect","not divided","not reported","one way","other","parking lot","ramp","roundabout","T-intersect","traffic route","unknown way","unknown intersect","Y-intersect","temp","snow")))
```

#### AUC-ROC

The plot below shows the ROC of the model, along with the threshold value. The AUC is 0.580, which is only slightly better than chance.

```{r}

roc_obj <- roc(base_data_filtered_glm$`Damage Class`,
               fitted(model_3), print.thres="best", print.auc=T,plot=F, legacy.axes=T)
plot(roc_obj, print.thres="best", print.auc=TRUE, legacy.axes=T)
```
